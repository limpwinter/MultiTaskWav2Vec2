{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9c4c9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from russian_g2p.Grapheme2Phoneme import Grapheme2Phoneme\n",
    "# from russian_g2p.Accentor import Accentor\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2FeatureExtractor\n",
    "import numpy as np\n",
    "# import torchaudio\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "# import os\n",
    "# import pathlib\n",
    "import itertools\n",
    "from Transcriptor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fe963b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5d38d825",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_folder = Path('../data/train/')\n",
    "MODEL_ID = \"facebook/wav2vec2-large-xlsr-53\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea1c441d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_lg\")\n",
    "# AUDIO_MAXLEN=246000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f3fd4be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                                   id  \\\n45   0798f44c844772fb5885ae6404daafbc   \n90   b777eaec4a3ab1d58cc98102b4531fc0   \n145  37a13270e722b0bbc08b0e7833cdffb6   \n55   e6db2e4fcb62341ba429b4d37c41c8b1   \n51   16c9436e73ac4273e503f74838b8fb5f   \n\n                                   audio_filepath                 text  \\\n45   crowd/7/0798f44c844772fb5885ae6404daafbc.wav               хватит   \n90   crowd/0/b777eaec4a3ab1d58cc98102b4531fc0.wav  майдан на смотрешке   \n145  crowd/9/37a13270e722b0bbc08b0e7833cdffb6.wav              абакана   \n55   crowd/8/e6db2e4fcb62341ba429b4d37c41c8b1.wav                 агат   \n51   crowd/9/16c9436e73ac4273e503f74838b8fb5f.wav            поронайск   \n\n     duration  \n45      1.173  \n90      1.300  \n145     1.400  \n55      1.416  \n51      1.685  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>audio_filepath</th>\n      <th>text</th>\n      <th>duration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>45</th>\n      <td>0798f44c844772fb5885ae6404daafbc</td>\n      <td>crowd/7/0798f44c844772fb5885ae6404daafbc.wav</td>\n      <td>хватит</td>\n      <td>1.173</td>\n    </tr>\n    <tr>\n      <th>90</th>\n      <td>b777eaec4a3ab1d58cc98102b4531fc0</td>\n      <td>crowd/0/b777eaec4a3ab1d58cc98102b4531fc0.wav</td>\n      <td>майдан на смотрешке</td>\n      <td>1.300</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>37a13270e722b0bbc08b0e7833cdffb6</td>\n      <td>crowd/9/37a13270e722b0bbc08b0e7833cdffb6.wav</td>\n      <td>абакана</td>\n      <td>1.400</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>e6db2e4fcb62341ba429b4d37c41c8b1</td>\n      <td>crowd/8/e6db2e4fcb62341ba429b4d37c41c8b1.wav</td>\n      <td>агат</td>\n      <td>1.416</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>16c9436e73ac4273e503f74838b8fb5f</td>\n      <td>crowd/9/16c9436e73ac4273e503f74838b8fb5f.wav</td>\n      <td>поронайск</td>\n      <td>1.685</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(train_data_folder / Path(\"10min.jsonl\"), lines=True).sort_values('duration')\n",
    "# data[:16]['text'].values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f90702b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data['text'] == ' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc9e6b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1, sr = torchaudio.load(\"../data/train/\" + \"crowd/6/57fc1fb6f9d82a5693a87dbedc38311d.wav\")\n",
    "# a2, sr = torchaudio.load(\"../data/train/\" + \"crowd/2/ebafee12dd8c1eb206f33b8af014c59f.wav\")\n",
    "# a3, sr = torchaudio.load(\"../data/train/\" + \"crowd/9/02c71d56001d2b9878664718e867d075.wav\")\n",
    "\n",
    "\n",
    "# a1, a2,a3 = np.array(a1).squeeze(),np.array(a2).squeeze(), np.array(a3).squeeze()\n",
    "# # l = max(len(a1),len(a2))\n",
    "# # s = np.array([np.pad(a1,(0,l - len(a1))), \n",
    "# #               np.pad(a2.squeeze(),(0,l - len(a2)))])\n",
    "# s2 = [a1,a2,a3]\n",
    "# s3 = processor(s2,sampling_rate=16_000, \n",
    "#                                    return_tensors='np',padding=True).input_values.squeeze()\n",
    "# s3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cba3520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True,\n",
    "                                             return_attention_mask=False)\n",
    "# accentor = Accentor()\n",
    "# transcriptor = Grapheme2Phoneme()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05bb0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters = [x for x in \"абвгдеёжзиклмнопрстуфхцчшщъыьэюя \"]\n",
    "# phonems = ['A', 'A0', 'A0l', 'Al', 'B', 'B0', 'B0l', 'Bl', 'D', 'D0', 'D0l',\n",
    "#            'DZ', 'DZ0', 'DZ0l', 'DZH', 'DZH0', 'DZH0l', 'DZHl', 'DZl', 'Dl',\n",
    "#            'E', 'E0', 'E0l', 'El', 'F', 'F0', 'F0l', 'Fl', 'G', 'G0', 'G0l',\n",
    "#            'GH', 'GH0', 'GH0l', 'GHl', 'Gl', 'I', 'I0', 'I0l', 'Il', 'J0',\n",
    "#            'J0l', 'K', 'K0', 'K0l', 'KH', 'KH0', 'KH0l', 'KHl', 'Kl', 'L',\n",
    "#            'L0', 'L0l', 'Ll', 'M', 'M0', 'M0l', 'Ml', 'N', 'N0', 'N0l', 'Nl',\n",
    "#            'O', 'O0', 'O0l', 'Ol', 'P', 'P0', 'P0l', 'Pl', 'R', 'R0', 'R0l',\n",
    "#            'Rl', 'S', 'S0', 'S0l', 'SH', 'SH0', 'SH0l', 'SHl', 'Sl', 'T', 'T0',\n",
    "#            'T0l', 'TS', 'TS0', 'TS0l', 'TSH', 'TSH0', 'TSH0l', 'TSHl', 'TSl',\n",
    "#            'Tl', 'U', 'U0', 'U0l', 'Ul', 'V', 'V0', 'V0l', 'Vl', 'Y', 'Y0',\n",
    "#            'Y0l', 'Yl', 'Z', 'Z0', 'Z0l', 'ZH', 'ZH0', 'ZH0l', 'ZHl', 'Zl', 'sil']\n",
    "# pos_tags = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CONJ\", \"CCONJ\",\n",
    "#             \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \"PRON\",\n",
    "#             \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\",\n",
    "#             \"SPACE\"]\n",
    "#\n",
    "# char_to_num = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=characters, oov_token=\"\")\n",
    "#\n",
    "# num_to_char = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "#\n",
    "# phn_to_num = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=phonems, oov_token=\"\")\n",
    "#\n",
    "# num_to_phn = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=phn_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "#\n",
    "# tags_to_num = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=pos_tags, oov_token=\"\")\n",
    "#\n",
    "# num_to_pos = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=tags_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a357be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_words = {'+б+а+н+к+о+м+а+т+': 'банкома+т',\n",
    "#              \"+к+о+л+е+с+а+х+\": \"коле+сах\",\n",
    "#              \"+ч+е+т+в+е+р+т+а+я+\": \"четверта+я\",\n",
    "#              \"+а+к+т+е+р+о+м+\": \"акте+ром\",\n",
    "#              \"+п+ю+р+е+\": \"пюре+\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d39e420b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d49329df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, df,\n",
    "                 batch_size,\n",
    "                 train=True):\n",
    "\n",
    "        self.df = df.copy().sort_values('duration')  # сортирока чтобы  при паддинге занимать меньше места\n",
    "        self.batch_size = batch_size\n",
    "        self.train = train\n",
    "        self.n = len(self.df)\n",
    "\n",
    "    def __get_input(self, wav_batch):\n",
    "        processed_waves = feature_extractor(wav_batch,\n",
    "                                            sampling_rate=16_000,\n",
    "                                            return_tensors='np',\n",
    "                                            padding=True,\n",
    "                                            padding_value=0.0).input_values.squeeze()\n",
    "        return processed_waves\n",
    "\n",
    "    def __get_waves(self, wav_path):\n",
    "        if self.train:\n",
    "            wav_file, sr = torchaudio.load(\"../data/train/\" + wav_path)\n",
    "        else:\n",
    "            wav_file, sr = torchaudio.load(\"../data/test/\" + wav_path)\n",
    "        assert sr == 16_000\n",
    "        return np.array(wav_file).squeeze()\n",
    "\n",
    "    def __get_phn_emb(self, text: str):\n",
    "        # разбиваем на слова\n",
    "        text = [[word] for word in text.split(\" \")]\n",
    "\n",
    "        # ставим ударения и заменяем \"сломанные\" слова\n",
    "        accented = accentor.do_accents(text)[0]\n",
    "        accented = [bad_words.get(word) if word in bad_words else word for word in accented]\n",
    "        # создаем и кодируем транскрипции\n",
    "        transcription = [transcriptor.word_to_phonemes(elem) for elem in accented]\n",
    "        transcription = np.array(transcription, dtype=np.ndarray)\n",
    "        transcription = [np.append(lst, ['PAD']) for lst in transcription]\n",
    "        transcription[-1] = transcription[-1][:-1]\n",
    "        #         transcription\n",
    "        merged = list(itertools.chain.from_iterable(transcription))\n",
    "        # phonems_array =  __get_phonems_array(text)\n",
    "        return phn_to_num(merged)\n",
    "\n",
    "    def __get_pos_emb(self, text: str):\n",
    "        doc = nlp(text.replace(\" \", \"  \"))\n",
    "        tagged = [w.pos_ for w in doc]\n",
    "        return tags_to_num(tagged)\n",
    "\n",
    "    def __get_text_emb(self, text: str):\n",
    "        emb = list(text)\n",
    "        return char_to_num(emb)\n",
    "\n",
    "    def __pad_batch_arrays(self, batch):\n",
    "        padded_batch = []\n",
    "        l = [len(elem) for elem in batch]\n",
    "        print(l)\n",
    "        l = max(l)\n",
    "        print(l)\n",
    "        for elem in batch:\n",
    "            elem = tf.pad(elem, [[0, l - len(elem)]])\n",
    "            padded_batch.append(elem)\n",
    "        return np.asarray(padded_batch)\n",
    "\n",
    "    def __get_data(self, batches):\n",
    "        # Generates data containing batch_size samples\n",
    "\n",
    "        paths_batch = batches['audio_filepath']\n",
    "\n",
    "        text_batch = batches['text']\n",
    "\n",
    "        x_batch = [self.__get_waves(X) for X in paths_batch]\n",
    "\n",
    "        x_batch = self.__get_input(x_batch)  # Padded\n",
    "\n",
    "        y_text_batch = np.asarray([self.__get_text_emb(y) for y in text_batch])\n",
    "        y_text_batch = self.__pad_batch_arrays(y_text_batch)\n",
    "\n",
    "        y_phn_batch = np.asarray([self.__get_phn_emb(y) for y in text_batch])\n",
    "        y_phn_batch = self.__pad_batch_arrays(y_phn_batch)\n",
    "\n",
    "        y_pos_tags_batch = np.asarray([self.__get_text_emb(y) for y in text_batch])\n",
    "        y_pos_tags_batch = self.__pad_batch_arrays(y_pos_tags_batch)\n",
    "\n",
    "        return x_batch, tuple([y_text_batch, y_phn_batch, y_pos_tags_batch])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        batches = self.df[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        data, labels = self.__get_data(batches)\n",
    "        return data, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8ab28e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['audio'] = data['audio_filepath'].map(preprocess_audio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "87a25c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['transcription'] = data['text'].map(create_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1e82d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['POS_TAGS'] = data['text'].map(create_pos_tags)\n",
    "# elements = [([1, 2, 3], [10]),\n",
    "#             ([4, 5], [11, 12])]\n",
    "# dataset = tf.data.Dataset.from_generator(\n",
    "#     lambda: iter(elements), (tf.int32, tf.int32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c697dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.padded_batch(2,\n",
    "#     padded_shapes=([None], [None]),\n",
    "#     padding_values=(0, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "659fd7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 19, 7, 4, 9, 14, 14, 25, 24, 4, 4, 6, 7, 18, 15, 10]\n",
      "25\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'Transcriptor' has no attribute '_DataGenerator__get_phonems_array'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\LIMPWI~1\\AppData\\Local\\Temp/ipykernel_16648/4274569625.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# % % time\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mgen\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mDataGenerator\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mbatch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgen\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\LIMPWI~1\\AppData\\Local\\Temp/ipykernel_16648/3824509302.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     88\u001B[0m         \u001B[0mbatches\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mindex\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mindex\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 89\u001B[1;33m         \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_data\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     90\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\LIMPWI~1\\AppData\\Local\\Temp/ipykernel_16648/3824509302.py\u001B[0m in \u001B[0;36m__get_data\u001B[1;34m(self, batches)\u001B[0m\n\u001B[0;32m     76\u001B[0m         \u001B[0my_text_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__pad_batch_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_text_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 78\u001B[1;33m         \u001B[0my_phn_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_phn_emb\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0my\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtext_batch\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     79\u001B[0m         \u001B[0my_phn_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__pad_batch_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_phn_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\LIMPWI~1\\AppData\\Local\\Temp/ipykernel_16648/3824509302.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     76\u001B[0m         \u001B[0my_text_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__pad_batch_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_text_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     77\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 78\u001B[1;33m         \u001B[0my_phn_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_phn_emb\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0my\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtext_batch\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     79\u001B[0m         \u001B[0my_phn_batch\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__pad_batch_arrays\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_phn_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\LIMPWI~1\\AppData\\Local\\Temp/ipykernel_16648/3824509302.py\u001B[0m in \u001B[0;36m__get_phn_emb\u001B[1;34m(self, text)\u001B[0m\n\u001B[0;32m     39\u001B[0m         \u001B[1;31m# #         transcription\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     40\u001B[0m         \u001B[1;31m# merged = list(itertools.chain.from_iterable(transcription))\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 41\u001B[1;33m         \u001B[0mphonems_array\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTranscriptor\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__get_phonems_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtext\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     42\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mphn_to_num\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mphonems_array\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'Transcriptor' has no attribute '_DataGenerator__get_phonems_array'"
     ]
    }
   ],
   "source": [
    "# % % time\n",
    "gen = DataGenerator(data, batch_size=16)\n",
    "batch = gen.__getitem__(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc02b61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(16, 25)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c069ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.7297432e-05,  2.7297432e-05,  2.7297432e-05, ...,\n         2.7297432e-05,  2.7297432e-05,  2.7297432e-05],\n       [-8.3034823e-04, -8.3034823e-04, -8.3034823e-04, ...,\n        -8.3034823e-04, -8.3034823e-04, -8.3034823e-04],\n       [ 1.1135483e-02,  3.4229627e-03, -1.7187169e-03, ...,\n         8.5212290e-04,  8.5212290e-04,  8.5212290e-04],\n       ...,\n       [-1.0303539e-01, -1.0303539e-01, -1.0303539e-01, ...,\n        -1.0303539e-01, -1.0303539e-01, -1.0303539e-01],\n       [ 1.7044069e-01,  1.7044069e-01,  2.3104294e-01, ...,\n        -1.1366010e-02, -1.1366010e-02, -1.1366010e-02],\n       [ 2.3604168e-04,  2.3604168e-04,  2.3604168e-04, ...,\n         4.1406229e-02,  3.6036205e-02,  4.1406229e-02]], dtype=float32)"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8a4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['audio'][0].pad\n",
    "# wavs = [tf.squeeze(data_10mins['audio'][0]),tf.squeeze(data_10mins['audio'][1]),tf.squeeze(data_10mins['audio'][2])]\n",
    "# nums = [1,2,3]\n",
    "# d = tf.data.Dataset.from_tensor_slices(\n",
    "#     (wavs, nums))\n",
    "# tf.keras.utils.to_categorical(0,num_classes=2)\n",
    "# characters = [x for x in \"абвгдеёжзиклмнопрстуфхцчшщъыьэюя \"]\n",
    "# char_to_num = tf.keras.layers.StringLookup(vocabulary=characters,oov_token=\"\")\n",
    "# characters = [x for x in \"абвгдеёжзиклмнопрстуфхцчшщъыьэюя \"]\n",
    "# phonems = characters # ЗАПОЛИНИТЬ СПИСОК МОРФЕМ\n",
    "# pos_tags = [\"ADJ\", \"ADP\", \"ADV\", \"AUX\", \"CONJ\", \"CCONJ\",\n",
    "#             \"DET\", \"INTJ\", \"NOUN\", \"NUM\", \"PART\", \"PRON\", \n",
    "#             \"PROPN\", \"PUNCT\", \"SCONJ\", \"SYM\", \"VERB\", \"X\", \n",
    "#             \"SPACE\"]\n",
    "# char_to_num = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=characters, oov_token=\"\")\n",
    "# num_to_char = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "# phn_to_num = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=phonems, oov_token=\"\")\n",
    "# num_to_phn = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=phn_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "# tags_to_num = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=pos_tags, oov_token=\"\")\n",
    "# num_to_pos = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=tags_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n",
    "\n",
    "# tags_to_num = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=pos_tags, oov_token=\"\")\n",
    "# num_to_pos = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=tags_to_num.get_vocabulary(), oov_token=\"\", invert=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ъ'\n",
    "\n",
    "text = [[word] for word in text.split(\" \")]\n",
    "accented = accentor.do_accents(text)[0]\n",
    "print(accented)\n",
    "bad_words = {'+б+а+н+к+о+м+а+т+': 'банкома+т',\n",
    "             \"+к+о+л+е+с+а+х+\": \"коле+сах\",\n",
    "             \"+ч+е+т+в+е+р+т+а+я+\": \"четверта+я\",\n",
    "             \"+а+к+т+е+р+о+м+\": \"акте+ром\",\n",
    "             \"+п+ю+р+е+\": \"пюре+\"}\n",
    "accented = [bad_words.get(word) if word in bad_words else word for word in accented]\n",
    "print(accented)\n",
    "transcription = [transcriptor.word_to_phonemes(elem) for elem in accented]\n",
    "transcription = np.array(transcription, dtype=np.ndarray)\n",
    "print(transcription)\n",
    "transcription = [np.append(lst, ['PAD']) for lst in transcription]\n",
    "print(transcription)\n",
    "transcription[-1] = transcription[-1][:-1]\n",
    "# transcription\n",
    "merged = list(itertools.chain.from_iterable(transcription))\n",
    "merged\n",
    "# doc = nlp(text.replace(\" \",\"  \"))\n",
    "# tags = [w.pos_ for w in doc]\n",
    "\n",
    "# # t = tags_to_num(tags)\n",
    "# # tf.strings.reduce_join(num_to_pos(t)).numpy().decode().replace(\"SPACE\",\" \")\n",
    "# # num_to_char()\n",
    "# print(tags_to_num(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97820a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['a']\n",
    "# list(lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacf4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad to the smallest per-batch size that fits all elements.\n",
    "# B = A.padded_batch(2)\n",
    "# for element in A:\n",
    "#       print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m1 = ['first','second','third']\n",
    "# m2 = [1,2,3]\n",
    "# d = tf.data.Dataset.from_tensor_slices((m1,m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c7bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for elem in d.take(1):\n",
    "#     print(elem[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bf9a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = 'сбер какая у меня комиссия за снятие денег через банкомат'\n",
    "# sentence =  [[word] for word in sentence.split(\" \")]\n",
    "# accented = accentor.do_accents(sentence)[0]\n",
    "# print(accented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34349f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accented = accentor.do_accents(sentence)\n",
    "# bad_words = {'+б+а+н+к+о+м+а+т+':'банкома+т'}\n",
    "# for lst in accented:\n",
    "#     print(lst)\n",
    "#     if lst[0] in bad_words.keys():\n",
    "#         lst[0] = bad_words.get(lst[0])\n",
    "# accented = [bad_words.get(word) if word in bad_words else word for word in accented]\n",
    "# print(accented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51321e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription = [transcriptor.word_to_phonemes(elem) for elem  in accented]\n",
    "# # accented = accentor.do_accents([['банкомат'], ['диалог']])\n",
    "# transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription = np.array(transcription, dtype=np.ndarray) # Скорее всего нужен будет другой формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = tf.data.Dataset.from_tensor_slices(data['audio_filepath'].values)\n",
    "# d = tf.data.Dataset.from_tensor_slices(\n",
    "#     (\n",
    "#     list(data['audio_filepath'].values),\n",
    "#     list(data['text'].values))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69fa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocals_phonemes = {'U0', 'U', 'O0', 'O', 'A0', 'A', 'E0', 'E', 'Y0', 'Y', 'I0', 'I',\n",
    "                   'U0l', 'Ul', 'O0l', 'Ol', 'A0l', 'Al', 'E0l', 'El', 'Y0l', 'Yl', 'I0l', 'Il'}\n",
    "voiced_weak_phonemes = {'J0', 'V0', 'V', 'N0', 'N', 'L0', 'L', 'M0', 'M', 'R0', 'R',\n",
    "                        'J0l', 'V0l', 'Vl', 'N0l', 'Nl', 'L0l', 'Ll', 'M0l', 'Ml', 'R0l', 'Rl'}\n",
    "voiced_strong_phonemes = {'B', 'B0', 'G', 'G0', 'D', 'D0', 'Z', 'Z0', 'ZH', 'ZH0',\n",
    "                          'GH', 'GH0', 'DZ', 'DZ0', 'DZH', 'DZH0',\n",
    "                          'Bl', 'B0l', 'Gl', 'G0l', 'Dl', 'D0l', 'Zl', 'Z0l', 'ZHl', 'ZH0l',\n",
    "                          'GHl', 'GH0l', 'DZl', 'DZ0l', 'DZHl', 'DZH0l'}\n",
    "deaf_phonemes = {'K', 'K0', 'P', 'P0', 'S', 'S0', 'T', 'T0', 'F', 'F0', 'KH', 'KH0',\n",
    "                 'TS', 'TS0', 'TSH', 'TSH0', 'SH', 'SH0',\n",
    "                 'Kl', 'K0l', 'Pl', 'P0l', 'Sl', 'S0l', 'Tl', 'T0l', 'Fl', 'F0l', 'KHl', 'KH0l',\n",
    "                 'TSl', 'TS0l', 'TSHl', 'TSH0l', 'SHl', 'SH0l'}\n",
    "russian_phonemes_set = vocals_phonemes | voiced_weak_phonemes |\n",
    "voiced_strong_phonemes | deaf_phonemes | {'sil'}\n",
    "russian_phonemes_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in d:\n",
    "#     print(e)\n",
    "# list(data['audio_filepath'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5586483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_audio(audio_binary):\n",
    "#     audio, _ = tf.audio.decode_wav(contents=audio_binary)\n",
    "#     print(type(audio))\n",
    "#     processed_wav = tf.squeeze(processor(audio,sampling_rate=16_000,return_tensors='tf').input_values,axis=-1)\n",
    "#     return processed_wav\n",
    "\n",
    "# def decode_audio_tf(audio_binary):\n",
    "#     return tf.numpy_function(decode_audio,[audio_binary],tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552ff951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_label(file_path):\n",
    "#     file_path = file_path.decode('utf-8')\n",
    "#     idx = file_path.split('/')[-1].split('.')[-2]\n",
    "#     label = data[data['id'] == idx]['text'][0]\n",
    "#     return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea224e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_waveform_and_label(file_path, labels):\n",
    "#     audio_binary = tf.io.read_file(\"../data/train/\" + file_path)\n",
    "#     waveform = decode_audio(audio_binary)\n",
    "#     return file_path,waveform, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31df2f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# d = (d.map(\n",
    "#     map_func=get_waveform_and_label,\n",
    "#     num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     .padded_batch(batch_size)\n",
    "#     .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # s = 'crowd/6/57fc1fb6f9d82a5693a87dbedc38311d.wav'\n",
    "# get_label('crowd/6/57fc1fb6f9d82a5693a87dbedc38311d.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385acc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[data['id'] == '57fc1fb6f9d82a5693a87dbedc38311d']['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for e in d:\n",
    "#     print(e)\n",
    "# def load(path):\n",
    "#     return torchaudio.load(path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534fdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wav_files = \"../data/train/\" + data['audio_filepath']\n",
    "# wav_files = wav_files.map(load).values\n",
    "# wav_files = tf.squeeze(processor(wav_files,sampling_rate=16_000,return_tensors='tf').input_values,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1820d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb335d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}